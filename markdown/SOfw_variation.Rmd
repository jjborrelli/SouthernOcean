---
title: "Variation in the Southern Ocean Food Web"
author: "Jonathan J. Borrelli"
output: 
  html_document:
    toc: true
    theme: united
  
---

```{r chunks, echo = F}
require(knitr)
opts_chunk$set(message = F, comment = NA, fig.width = 7, fig.height = 7)
```

# Initial Set-up  

Load required libraries:   

```{r loadLIB}
require(igraph)
require(NetIndices)
require(reshape2)
require(ggplot2)
require(devtools)
require(vegan)
require(data.table)
```

Source code for functions to describe web properties  

```{r SOURCEcode}
url <- "https://raw.githubusercontent.com/jjborrelli/Ecological-Networks/master/FoodWebs/Rscripts/web_functions.R"
source_url(url)
```


Load in the data  

```{r readDATA, cache = T}
s.ocean <- read.csv("http://esapubs.org/archive/ecol/E092/097/diet.csv")
```

# Functions
```{r}
webPROPS <- function(graph){
  adj <- get.adjacency(graph, sparse = F)
  gind <- GenInd(adj)
  diam <- diameter(graph)
  avpath <- average.path.length(graph)
  cluster <- transitivity(graph)
  cannibals <- sum(diag(adj))
  
  degrees <- degree(graph, mode = "all")
  indegrees <- degree(graph, mode = "in")
  outdegrees <- degree(graph, mode = "out")
  
  numBas <- length(indegrees[which(indegrees == 0)])
  numTop <- length(outdegrees[which(outdegrees == 0)])
  basal <- (numBas/gind$N) * 100
  top <- (numTop/gind$N) * 100
  int <- ((gind$N - (numBas + numTop))/gind$N) * 100
  
  web.props <- data.frame(N = gind$N, L = gind$Ltot, LD = gind$LD, C = gind$C, D = diam,
             AvgPath = avpath, ClCoef = cluster, Can = cannibals, Bas = basal, Top = top, Int = int)
  return(web.props)
}
```


```{r}
permutes_rc <- function(mat, iter = 100){
  require(igraph)
  require(data.table)
  
  pattern1 <- matrix(c(0,1,1,0), nrow = 2, ncol = 2)
  pattern2 <- matrix(c(1,0,0,1), nrow = 2, ncol = 2)
  count <- 0
  
  mat.list <- list()
  
  while(count < iter){
    srow <- sample(1:nrow(mat), 2)
    scol <- sample(1:ncol(mat), 2)
    
    test <- mat[srow, scol]
    
    if(sum(test == pattern1) == 4){
      count <- count + 1
      mat[srow, scol] <- pattern2
      g <- graph.adjacency(mat)
      mat.list[[count]] <- motif_counter(list(g), web = i)
      
      next
    } else if(sum(test == pattern2) == 4){
      count <- count + 1
      mat[srow, scol] <- pattern1
      g <- graph.adjacency(mat)
      mat.list[[count]] <- motif_counter(list(g), web = i)
      
      next
    } else {next}
  }
  
  matrices <- rbindlist(mat.list)
  return(matrices)
}
```


# Southern Ocean Food Web  

```{r intoIGRAPH}
el.df <- data.frame(pred = s.ocean$PREDATOR_NAME, prey = s.ocean$PREY_NAME)
  
SOgraph <- graph.edgelist(unique(as.matrix(el.df[,1:2])))

SOadjacency <- get.adjacency(SOgraph, sparse = F)
```

First take a quick look at what the food web looks like. Here I plot the web by trophic level by setting the layout (code shown below). Nodes are plotted with trophic position along the y-axis and plotted along the x-axis according to a random uniform distribution (`runif(x, 0, 1)`).  

```{r unseenCODE, cache = T, echo = F}
gind <- GenInd(SOadjacency)
tind <- TrophInd(SOadjacency)
```

```{r wholeFW, fig.cap = "The Southern Ocean food web"}
par(mar = c(0,0,0,0))
layouts <- matrix(c(runif(gind$N), tind$TL), ncol = 2)
plot.igraph(SOgraph, layout = layouts, vertex.label = NA, edge.arrow.size = .5, 
            vertex.size = 1)
```

## Web level properties 

The `NetIndices` and `igraph` packages have functions to calculate a number of commonly used food web indices. The function `GenInd` from the `NetIndices` library easily calculates the number of nodes ($N$), total number of links ($L$), link density ($\frac{L}{N} = LD$), and connectance (along with some other indices that are not relevant to this dataset). Connectance in this case is calculated as: $$C = \frac{L}{N*(N-1)}$$  
  
The `diameter` is the single longest path between two nodes. The `average.path.length` is the mean number of links between any two nodes in the web. The clustering coefficient (or `transitivity`) is the probability that the nearest neighbors of a given vertex are themselves connected. A high clustering coefficient is an indication that a network has "small world" properties. The sum of the diagonal elements of the adjacency matrix gives the number of species that are cannibalistic, with links that loop back to themselves.   
  
Species in a food web may be either basal, intermediate, or top. These positions may be determined simply by examining the degree of each node. The number of links pointing towards a node is its in-degree and the number of links pointing away from a node is the out-degree. In-degree is therefore a measure of how many species the node of interest preys upon (generality) while out-degree is the number of predators a given node has (vulnerability). Basal nodes will have an in-degree of 0, and likewise top species will have an out-degree of 0. Once the number of basal and top species are found, the number of intermediate species is simply the remainder. 


```{r webProps, cache = T}
  diam <- diameter(SOgraph)
  avpath <- average.path.length(SOgraph)
  cluster <- transitivity(SOgraph)
  cannibals <- sum(diag(SOadjacency))
  
  degrees <- degree(SOgraph, mode = "all")
  indegrees <- degree(SOgraph, mode = "in")
  outdegrees <- degree(SOgraph, mode = "out")
  
  numBas <- length(indegrees[which(indegrees == 0)])
  numTop <- length(outdegrees[which(outdegrees == 0)])
  basal <- (numBas/gind$N) * 100
  top <- (numTop/gind$N) * 100
  int <- ((gind$N - (numBas + numTop))/gind$N) * 100
  
  web.props <- data.frame(N = gind$N, L = gind$Ltot, LD = gind$LD, C = gind$C, D = diam,
             AvgPath = avpath, ClCoef = cluster, Can = cannibals, Bas = basal, Top = top, Int = int)
```
```{r echo = F}
print(web.props)
```

There are a total of `r web.props$N` species with `r web.props$L` interactions among them. The longest chain described in this food web is `r web.props$D` but the average chain is 
`r web.props$AvgPath`.  

## Randomized properties

For this first randomization I will permute the prey of each species

```{r, eval = F}
preys <- unique(el.df)$prey
el.df2 <- unique(el.df)
w.props <- list()
for(i in 1:100){
  perm <- sample(preys, replace = F)
  el.df2 <- cbind(el.df2, perm)
  
  new.df <- data.frame(el.df2$pred, perm)
  perm.g <- graph.edgelist(as.matrix(new.df))
  
  w.props[[i]] <- webPROPS(perm.g)
  print(i)
}
rbindlist(w.props)
```

## 1990 to 2000
Here I cleave out the portion of the dataset that refers to observations with end dates between 1990 and 2000.

```{r}
so.ode <- as.character(s.ocean$OBSERVATION_DATE_END)
so.ode.split <- strsplit(so.ode, split = "/")

year <- c()
for(i in 1:length(so.ode.split)){
  year[i] <- so.ode.split[[i]][3]
}
s.ocean2 <- cbind(s.ocean, year)
so_90s <- s.ocean2[which(as.numeric(s.ocean2$year) >= 25 & as.numeric(s.ocean2$year) <= 35),]
so_90s <- droplevels(so_90s)
m2 <- split(so_90s, f = so_90s$year)
```

The `m2` object is a large list of data frames where each is a subset of the original Southern Ocean diet database consisting of observations from a given year in the range of 1990-2000. 

I can convert these into annual food webs. 

```{r}
year.g <- list()  
for (i in 1:length(levels(so_90s$year))){
  
  el.df <- data.frame(pred = m2[[i]]$PREDATOR_NAME, prey = m2[[i]]$PREY_NAME)
  
  g <- graph.edgelist(unique(as.matrix(el.df[,1:2])))
  
  year.g[[i]] <- g 
}
names(year.g) <- levels(so_90s$year)
```

Plot webs by year
```{r}
y.ad <- lapply(year.g, get.adjacency, sparse = F)
y.tind <- lapply(y.ad, function(x){TrophInd(x)$TL})

myt <- melt(y.tind)
ggplot(myt, aes(x = value, y = ..density..)) + geom_histogram(binwidth = .5) + facet_wrap(~L1) + xlab("Trophic Position")

y.lay <- list()
for(i in 1:length(y.tind)){
  y.lay[[i]] <- matrix(c(runif(length(y.tind[[i]])), y.tind[[i]]), ncol = 2)
}
```


```{r yearPLOT, fig.width = 8, fig.height = 8}
for (i in 1:length(year.g)){
  plot.igraph(year.g[[i]], layout = y.lay[[i]], edge.arrow.size = .5, vertex.label = NA,
              vertex.size = 5, margin = 0, main = levels(so_90s$year)[i])
  #text(0, 0, label = levels(so_90s$year)[i], cex = 2)
}
```

```{r, cache = T}
year.props <- sapply(year.g, webPROPS)

year.props
```

Next I use the package `betalink` from Poisot et al. 2012 to determine the betadiversity of all pairs of annual networks.  
S = Dissimilarity in the species composition of communities  
OS = Dissimilarity of interactions established between species common to both realizations
WN = Dissimilarity of interactions
ST = Dissimilarity of interactions due to species turnover
```{r}
library(betalink)
test <- network_betadiversity(year.g)
bl.y <- list()
for(i in 1:10){
  bl.y[[i]] <- betalink(year.g[[i]], year.g[[i+1]])
}
timeline <- rbindlist(bl.y)
ggplot(melt(timeline), aes(x = rep(1991:2000, 4), y = value)) + geom_point() + geom_smooth(method = "glm") + scale_x_continuous(breaks = c(1991:2000)) + xlab("Year") + ylab("Dissimilarity") + facet_wrap(~variable)
```

#### Motif structure

```{r}
library(parallel)
library(doSNOW)
cl <- makeCluster(detectCores()-1)
registerDoSNOW(cl)
clusterExport(cl, list("permutes_rc", "graph.adjacency", "motif_counter"))

rands <- parLapply(cl, y.ad, function(x){r1 <- permutes_rc(x, 10000)
                                         r2 <- lapply(r1, graph.adjacency)
                                         r3 <- motif_counter(r2, webs = 1:1000)
                                         return(r3)})

stopCluster(cl)

r1 <- list()
n <- 30000
for(i in 1:length(y.ad)){
  r1[[i]] <- permutes_rc(y.ad[[i]], n)
  print(i)
}

mots <- motif_counter(year.g, webs = 1990:2000)
means1 <- t(sapply(r1, colMeans))
sds <- t(sapply(r1, function(x){apply(x, 2, sd)}))

cv <- apply(mots[,2:14], 2, function(x){sd(x)/mean(x)})
qss <- c(1, .5345, .0561, 1, 1, .037, .0428, .0891, .0866, .0101, 0, .0021, 0) #from subgraph paper

z1 <- (mots[,2:14] - means1[,2:14])/sds[,2:14]
z1[is.na(z1)] <- 0
boxplot(z1)
cv <- apply(z1, 2, function(x){sd(x)/mean(x)})
plot(abs(cv)~qss)

means.z <- colMeans(z1)
u1 <- means.z + 1.96*sqrt(apply(z1, 2, var)/11)
l1 <- means.z - 1.96*sqrt(apply(z1, 2, var)/11)

cols <- names(mots)[-1]
dens <- matrix(nrow = 11, ncol = length(cols))
for(i in 1:11){
  for(j in 1:length(cols)){
    #dens[i,j] <- sum(r1[[i]][[cols[j]]] < mots[i,j+1])/30000
    q <- quantile(r1[[i]][[cols[j]]], c(.025, .975))
    dens[i,j] <- mots[i,j+1] <= q[1] | mots[i,j+1] >= q[2]
  }
}
dens

sum(r1[[1]][[cols[1]]] >= mots[1, 2])/30000

year <- rep(1990:2000, each = 30000)
dats <- cbind(year, rbindlist(r1))
setwd("C:/Users/jjborrelli/Desktop/")
write.csv(dats, "permutes.csv")
```


### By location

```{r}
loc.ls <- lapply(m2, function(x){split(x, f = x$LOCATION)})
t(rbindlist(lapply(loc.ls, function(x){lapply(x, nrow)})))
m3 <- lapply(m2, droplevels)
loc.ls2 <- lapply(m3, function(x){split(x, f = x$LOCATION)})
loc.y.ls <- unlist(loc.ls2, recursive = F)


ly.g <- list()  
for (i in 1:length(loc.y.ls)){
  
  el.df <- data.frame(pred = loc.y.ls[[i]]$PREDATOR_NAME, prey = loc.y.ls[[i]]$PREY_NAME)
  
  g <- graph.edgelist(unique(as.matrix(el.df[,1:2])))
  
  ly.g[[i]] <- g 
  
}

ly.props <- sapply(ly.g, webPROPS)
ly.props
```



